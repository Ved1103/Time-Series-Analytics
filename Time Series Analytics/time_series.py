# -*- coding: utf-8 -*-
"""Time_series.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aHAUhYsY4pkxyoGiiZ7NGKg_aUVb4VE4

# **Introduction: Time Series Forecasting of Sales**
In today's data-driven world, businesses rely on accurate sales forecasting to make informed decisions about inventory management, resource allocation, marketing strategies, and financial planning. Time Series Forecasting plays a pivotal role in predicting future sales trends based on historical data. By leveraging statistical methods and machine learning algorithms, this project aims to provide a reliable solution for anticipating sales performance, which can significantly enhance business outcomes.

# **Dataset Preparation**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn import preprocessing
import matplotlib.pyplot as plt
# %matplotlib inline
plt.rc("font", size=14)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import seaborn as sns
import math
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import datetime as dt
sns.set()
sns.set(style="whitegrid", color_codes=True)

import warnings
warnings.filterwarnings("ignore")

sales_data = pd.read_excel('monthly-sales.xlsx')

sales_data.head()

sales_data.tail()

sales_data.info()

"""We analyzed the time series data, which spans from January 2008 to September 2013, and confirmed it meets key characteristics: it is continuous, sequential, evenly spaced (monthly), and unique (one data point per month). For convenience, we set the time interval (month) as the index. To prepare for model construction and evaluation, we split the data into training and testing sets. The training set includes data from January 2008 to May 2013, while the last four records (June 2013 to September 2013) are reserved as a holdout sample. This allows us to evaluate the model’s predictive accuracy by comparing its forecasts to actual values, ensuring its ability to generalize to unseen data."""

sales_data = sales_data.set_index('Month')  # Set the time variable as an index
sales_data.index =  pd.date_range(start=sales_data.index[0] , periods=len(sales_data), freq='MS')

sales_data_train = sales_data.iloc[:-4, :] # Train set
sales_data_test = sales_data.iloc[-4:, :] # Test set for validation

sales_data_train.index = pd.date_range(start=sales_data_train.index[0] , periods=len(sales_data_train), freq='MS')
sales_data_test.index = pd.date_range(start=sales_data_test.index[0] , periods=len(sales_data_test), freq='MS')

sales_data_train.shape, sales_data_test.shape

sales_data_test['Monthly Sales']

"""# Data Exploration

*   Visualize the Time Series
*   Determine Trend, Seasonal, and Error components
"""

fig, ax = plt.subplots()
ax.plot(sales_data_train.index, sales_data_train['Monthly Sales'])
ax.set_ylabel('Monthly Sales Amount')
ax.set_xlabel('Year')
ax.set_title('Time Series Plots of Sales Amount', size=18)

"""The time series plot of monthly sales data reveals a general upward trend, indicating that the company's sales have been increasing over time. To select suitable forecasting methods, the time series is analyzed by breaking it into systematic components—**level**, **trend**, and **seasonality**—and an unsystematic component called **noise**. These components represent the underlying patterns and random fluctuations in the data. Depending on how these components interact, they can be combined either additively or multiplicatively. In our dataset, these components are visually examined through decomposition plots, which are presented in the next section.

**Determine Trend, Seasonal, and Error components**
"""

from statsmodels.tsa.seasonal import seasonal_decompose
res = seasonal_decompose(sales_data_train['Monthly Sales'], model='additive', period=12)

fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(12,10), sharex= True)
res.observed.plot(ax=ax1)
ax1.set_ylabel('Observed Data')
res.seasonal.plot(ax=ax2)
ax2.set_ylabel('Seasonal')
res.trend.plot(ax=ax3)
ax3.set_ylabel('Trend')
res.resid.plot(ax=ax4)
ax4.set_ylabel('Reminder')

plt.xlabel("Year")

"""The decomposition plot shows our time series broken down into its three components: trend, seasonal and the error. Each of these components makes up our time series and helps us confirm what we saw in our initial time series plot.



*   The Trend line is confirmed that there is an upward trending.
*   The Seasonality subplot shows that the regularly occurring spike in sales each year changes in magnitude, ever so slightly. Our dataset definitely contains seasonality, and this suggests that any ARIMA models used for analysis will need seasonal differencing. The change in magnitude suggests that any ETS models will use a multiplicative method in the seasonal component.

*  The Error plot of the series presents a fluctuations between large and smaller errors as the time series goes on. Since the fluctuations are not consistent in magnitude then we will apply error in a multiplicative manner for any ETS models.

# **Data Analysis**

**Build the Forecasting Models**

 I analyzed the decomposition graphs to inform forecasting models on the business problem. In this section, I determine the appropriate measurements to apply to the ETS model and the (Seasonal) ARIMA. Then I compare both models based on in-sample errors.

### **ETS Models**

ETS stands for Error, Trend, and Seasonality, and are the three inputs in ETS models. From the decomposition plot, we can obtain the necessary information to define the terms for the ETS model.


*   The Trend line exhibits linear behavior so we will use an additive method.
*   The Seasonality changes in magnitude each year so a multiplicative method seems necessary.
*   The Error changes in magnitude as the series goes along so a multiplicative method will be used.
This leaves us with an ETS(M, A, M) model.
"""

# Import the relevant libraries
from statsmodels.tsa.exponential_smoothing.ets import ETSModel

sales_data_train = pd.Series(sales_data_train['Monthly Sales']).astype('float64')
ets_model = ETSModel(sales_data_train, error='mul', trend='add', seasonal = 'mul',
                     damped_trend=True, seasonal_periods=12, initial_level=sales_data_train.values.mean(), freq='MS')
ets_fitted = ets_model.fit()

print(ets_fitted.summary())

plt.figure(figsize=(10,8))
sales_data_train.plot(label='Original data')
ets_fitted.fittedvalues.plot(label='Statsmodels fit - ETS Model')
plt.title('Visualisation of Time Series Data and fitted data by ETS Model' , fontsize=16)
plt.ylabel("Monthly Sales Amount");
plt.xlabel("Year")
plt.legend();

pred_ets= ets_fitted.fittedvalues

"""**Evaluating In-Sample Accuracy (ETS Models)**

Now, I describe the in-sample errors based on ETS models. The in-sample error measures give us a look at how well our model is able to predict future values. Among the various Error Terms, I chose:



*   RMSE (Rooted Mean Squared Error)
*   MAE (Mean Absolute Error)
*   MAPE (Mean Absolute Percentage Error)
*   MASE (Mean Absolute Scaled Error)




"""

expected_ets = sales_data_train.values
predicted_ets = pred_ets.values

from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.metrics import mean_absolute_error

def mean_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean((y_true - y_pred) / y_true * 100)

def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def running_diff(arr, N):
    return np.array([arr[i] - arr[i-N] for i in range(N, len(arr))])

def mean_absolute_scaled_error(training_series, testing_series, prediction_series):
    errors_mean = np.abs(testing_series - prediction_series ).mean()
    d = np.abs(running_diff(training_series, 12) ).mean()
    return errors_mean/d

mse_ets  = mean_squared_error(expected_ets, predicted_ets)
rmse_ets = sqrt(mse_ets)
mae_ets  = mean_absolute_error(expected_ets, predicted_ets)
mpe_ets  = mean_percentage_error(expected_ets, predicted_ets)
mape_ets = mean_absolute_percentage_error(expected_ets, predicted_ets)
mase_ets = mean_absolute_scaled_error(expected_ets, expected_ets, predicted_ets)

print('In-Sample Error Measures of ETS Models:')
print('')
print('- RMSE: %.2f' % rmse_ets)
print('- MAE : %.2f' % mae_ets)
print('- MPE : %.2f' % mpe_ets)
print('- MAPE: %.2f' % mape_ets)
print('- MASE: %.2f' % mase_ets)

"""**Scale-dependent errors:**

The two most commonly used scale-dependent measures are the absolute errors(MAE) or squared errors(RMSE). When comparing forecast methods applied to one time series, or to several time series with the same units, the MAE is popular, because it is easy to both understand and compute. A forecast method that minimises the MAE will lead to forecasts of the median, while minimising the RMSE will lead to forecasts of the mean. Consequently, the RMSE is also widely used, despite being more difficult to interpret.

**Percentage errors**:

Percentage errors have the advantage of being unit-free, and so are frequently used to compare forecast performances between data sets. The most commonly used measure is MAPE.

**Scaled errors:**

Scaled errors were proposed by Hyndman & Koehler (2006) as an alternative to using percentage errors when comparing forecast accuracy across series with different units. They proposed scaling the errors based on the training MAE from a simple forecast method. A scaled error is less than 1, if it arises from a better forecast than the average naïve forecast computed on the training data. Conversely, it is greater than 1 if the forecast is worse than the average naïve forecast computed on the training data.

---
Two key measures we have to check are the RMSE, which shows the
in-sample standard deviation, and the MASE which can be used to compare forecasts of different models. We can see that the value of RMSE is about 34000 units around the mean. The MASE shows a fairly strong forecast at .38 with its value falling well below the generic 1.00, the commonly accepted MASE threshold for model accuracy.

# **Seasonal ARIMA**

In Time Series Analysis, we should start the analysis with a "stationary" data. make the data stationary. As the decomposition plots exhibit, the provided dataset seems to have seasonality and linear Trend. Augmented Dickey Fuller test reminds us the fact that the given data is not stationary
"""

# Augmented Dickey Fuller test
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from numpy import log
result = adfuller(sales_data_train.dropna())
print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])

"""By differencing data points, I make the time series stationary."""

# Plot
fig, axes = plt.subplots(3, 1, figsize=(10,8), dpi=100, sharex=True)

# Usual Differencing
axes[0].plot(sales_data_train, label='Original Series')
axes[0].plot(sales_data_train.diff(1), label='Usual Differencing')
axes[0].set_title('Usual Differencing')
axes[0].legend(loc='upper left', fontsize=10)
sales_data_diff = sales_data_train.diff(1)

# Seasinal Dei
axes[1].plot(sales_data_train, label='Original Series')
axes[1].plot(sales_data_train.diff(12), label='Seasonal Differencing', color='green')
axes[1].set_title('Seasonal Differencing')
axes[1].legend(loc='upper left', fontsize=10)

# Seasinal first differencing
axes[2].plot(sales_data_train, label='Original Series')
axes[2].plot(sales_data_diff.diff(12), label='Seasonal First Differencing', color='purple')
axes[2].set_title('Seasonal First Differencing')
axes[2].legend(loc='upper left', fontsize=10)
plt.suptitle('Monthly Sales', fontsize=16)
plt.show()

# Augmented Dickey Fuller test for Seasonal First Differencing Data
seasonal_first_differencing = sales_data_diff.diff(12)
result_seasonal_first_diff = adfuller(seasonal_first_differencing.dropna())
print('ADF Statistic for Seasonal First Differencing: %.4f' % result_seasonal_first_diff[0])
print('p-value for Seasonal First Differencing: %.4f' % result_seasonal_first_diff[1])

"""As you can see from the third plot, the original time series data is changed a stationary data after seasonal first differencing. This fact can be also confirmed by the p-value of Augmented Dickey Fuller test. Taking the seasonal first difference has now made our data stationary. Next, I find the optimal parameters based on the Time Series ACF and PACF graphs.

i. Time Series ACF and PACF
"""

from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf

fig = plt.figure(figsize=(10,8))
ax1 = fig.add_subplot(211)
fig=plot_acf(sales_data_train,  lags=25, ax=ax1)

ax2 = fig.add_subplot(212)
fig=plot_pacf(sales_data_train, lags=25,  ax=ax2)

plt.xlabel('Lag')
plt.suptitle('ACF and PACF plots for Initial Time Series', fontsize=16)
plt.show()

"""ii. Seasonal Difference ACF and PACF"""

seasonal_diff = running_diff(sales_data_train, 12)

fig = plt.figure(figsize=(10,8))
ax1 = fig.add_subplot(211)
fig=plot_acf(seasonal_diff, lags=25,  ax=ax1)

ax2 = fig.add_subplot(212)
fig=plot_pacf(seasonal_diff, lags=25,  ax=ax2)

plt.xlabel('Lag')
plt.suptitle('ACF and PACF plots for Seasonal Differencing Time Series', fontsize=16)
plt.show()

"""iii. Seasonal First Difference ACF and PACF"""

seasonal_diff_1 = running_diff(seasonal_diff, 1)

fig = plt.figure(figsize=(10,8))
ax1 = fig.add_subplot(211)
fig=plot_acf(seasonal_diff_1, lags=25,  ax=ax1)

ax2 = fig.add_subplot(212)
fig=plot_pacf(seasonal_diff_1, lags=25,  ax=ax2)

plt.xlabel('Lag')
plt.suptitle('ACF and PACF plots for Seasonal First Differenced Time Series', fontsize=16)
plt.show()

"""*   The seasonal first difference of the series has removed most of the significant lags from the ACF and PACF. It seems no more need for further differencing. The remaining correlation can be considered for using autoregressive and moving average terms. Therefore, the differencing terms will be d(1) and D(1).

*   The ACF plot shows a strong negative correlation at lag-1 which is confirmed in the PACF. This suggests an MA(1) model since there is only 1 significant lag. The seasonal lags (lag 12, 24, etc.) in the ACF and PACF do not have any significant correlation so there will be no need for seasonal autoregressive or moving average terms.
*  Therefore, the model terms for my ARIMA model are: ARIMA(0, 1, 1)(0, 1, 0)[12]. Note that the ACF and PACF results for the ARIMA(0, 1, 1)(0, 1, 0)[12] model shows no significantly correlated lags suggesting no need for adding additional AR() or MA() terms.

**Define the Seasonal ARIMA model**
"""

# Define model
model_sarima = sm.tsa.statespace.SARIMAX(endog = sales_data_train,
                                         order=(0, 1, 1), seasonal_order=(0,1,0,12),
                                         trend = 't', freq = 'MS',
                                         seasonal_periods =12,
                                         enforce_stationarity=False,
                                         enforce_invertibility=False)
# FIt Model
sarima_fitted = model_sarima.fit(dynamic=False)
print(sarima_fitted.summary())

"""Plotting residuals make us ensure there are no patterns. In other words, we can check for constant mean and variance of residuals."""

residuals = pd.DataFrame(sarima_fitted.resid)
residuals.plot()
plt.show()
residuals.plot(kind='kde')
plt.show()
print(residuals.describe())

# Compare the Original Time Series and Fitted values
sales_data_train.plot(label='Original data',figsize=(8,6))
sarima_fitted.fittedvalues.plot(label='Seasonal ARIMA - Statsmodels fit')
plt.ylabel("Monthly Sales Amount");
plt.xlabel("Year")
plt.title('Actual vs. Fitted Values', fontsize= 16)
plt.legend();

"""**Evaluating In-Sample Accuracy (Seasonal ARIMA)**"""

predicted_sarima = sarima_fitted.predict().values
expected_sarima = sales_data_train.values

mse_sarima  = mean_squared_error(expected_sarima, predicted_sarima)
rmse_sarima = sqrt(mse_sarima)
mae_sarima  = mean_absolute_error(expected_sarima, predicted_sarima)
mpe_sarima  = mean_percentage_error(expected_sarima, predicted_sarima)
mape_sarima = mean_absolute_percentage_error(expected_sarima, predicted_sarima)
mase_sarima = mean_absolute_scaled_error(expected_sarima, expected_sarima, predicted_sarima)

print('In-Sample Error Measures of Seasonal ARIMA Models:')
print(' ')
print('- RMSE : %f' % rmse_sarima)
print('- MAE  : %f' % mae_sarima)
print('- MPE  : %f' % mpe_sarima)
print('- MAPE : %f' % mape_sarima)
print('- MASE : %f' % mase_sarima)

"""So far, I have analysed the training part of time series data using ETS Models and Seasonal ARIMA. Then I compared the performance of each model with In-Sample Error Measures such as RMSE, MAPE and MASE. When comparing the two in-sample error measures we used, the ETS model does have a much narrower standard deviation(RMSE). Though the MASE value of ETS model is lower than that of Seasonal ARIMA, both are below 1.00, the generally accepted MASE threshold for model accuracy.
Next, I compare the prediction performance of both models using holdout samples.

# **Predict the Holdout Sample**
"""

# ETS Model for Validation
sales_data = pd.Series(sales_data['Monthly Sales']).astype('float64')
ets_model_holdout = ETSModel(sales_data, error='mul', trend='add', seasonal = 'mul',
                             damped_trend=True, seasonal_periods=12,
                             initial_level=sales_data_train.values.mean(), freq='MS')
ets_fitted_holdout = ets_model_holdout.fit()

ets_fitted_holdout.predict()[-4:]

# Seasonal ARIMA Model for Validation
model_sarima_holdout = sm.tsa.statespace.SARIMAX(endog = sales_data,
                                                 order=(0, 1, 1), seasonal_order=(0,1,0,12),
                                                 trend = 't', freq = 'MS',
                                                 seasonal_periods =12,
                                                 enforce_stationarity=False,
                                                 enforce_invertibility=False)
sarima_fitted_holdout = model_sarima_holdout.fit(dynamic=False)

sarima_fitted_holdout.predict()[-4:]

holdout_results = pd.DataFrame({'actual': sales_data_test['Monthly Sales'],
                                 'predicted_ETS': ets_fitted_holdout.predict()[-4:].values,
                                 'predicted_ARIMA': sarima_fitted_holdout.predict()[-4:].values },
                               index = sales_data_test.index)
holdout_results

plt.figure(figsize=(10, 6))
plt.plot(holdout_results.index, holdout_results['actual'], label='Actual Sales', marker='o')
plt.plot(holdout_results.index, holdout_results['predicted_ETS'], label='ETS Predictions', marker='x')
plt.plot(holdout_results.index, holdout_results['predicted_ARIMA'], label='ARIMA Predictions', marker='s')

plt.xlabel('Month')
plt.ylabel('Monthly Sales')
plt.title('Holdout Results Comparison')
plt.legend()
plt.grid(True)
plt.show()

# Holdout-Sample Errors Comparison
# ETS Model
mse_ets_hos  = mean_squared_error(sales_data_test['Monthly Sales'], holdout_results['predicted_ETS'])
rmse_ets_hos = sqrt(mse_ets_hos)
mae_ets_hos  = mean_absolute_error(sales_data_test['Monthly Sales'], holdout_results['predicted_ETS'])
mpe_ets_hos  = mean_percentage_error(sales_data_test['Monthly Sales'], holdout_results['predicted_ETS'])
mape_ets_hos = mean_absolute_percentage_error(sales_data_test['Monthly Sales'], holdout_results['predicted_ETS'])
mase_ets_hos = mean_absolute_scaled_error(sales_data_train.values, sales_data_test['Monthly Sales'], holdout_results['predicted_ETS'])

print('Holdout-Sample Error Measures of ETS Models:')
print(' ')
print('- RMSE : %.3f' % rmse_ets_hos)
print('- MAE  : %.3f' % mae_ets_hos)
print('- MPE  : %.3f' % mpe_ets_hos)
print('- MAPE : %.3f' % mape_ets_hos)
print('- MASE : %.3f' % mase_ets_hos)
print(' ')
# (Seasonal) ARIMA Model
mse_sarima_hos  = mean_squared_error(sales_data_test['Monthly Sales'], holdout_results['predicted_ARIMA'])
rmse_sarima_hos = sqrt(mse_sarima_hos)
mae_sarima_hos  = mean_absolute_error(sales_data_test['Monthly Sales'],  holdout_results['predicted_ARIMA'])
mpe_sarima_hos  = mean_percentage_error(sales_data_test['Monthly Sales'],  holdout_results['predicted_ARIMA'])
mape_sarima_hos = mean_absolute_percentage_error(sales_data_test['Monthly Sales'],  holdout_results['predicted_ARIMA'])
mase_sarima_hos = mean_absolute_scaled_error(sales_data_train.values, sales_data_test['Monthly Sales'],  holdout_results['predicted_ARIMA'])
print(' ')
print('Holdout-Sample Error Measures of Seasonal ARIMA Models:')
print(' ')
print('- RMSE : %.3f' % rmse_sarima_hos)
print('- MAE  : %.3f' % mae_sarima_hos)
print('- MPE  : %.3f' % mpe_sarima_hos)
print('- MAPE : %.3f' % mape_sarima_hos)
print('- MASE : %.3f' % mase_sarima_hos)

"""# **Forecast for the next 4 months of Sales**"""

# Seasonal ARIMA Model for Forecasting
model_sarima_final = sm.tsa.statespace.SARIMAX(sales_data, order=(0, 1, 1),
                                             seasonal_order=(0,1,0,12), trend = 't',
                                             seasonal_periods =12,
                                             enforce_stationarity=False, enforce_invertibility=False)
# FIt Model
sarima_fitted_final = model_sarima_final.fit(dynamic=False)

sarima_fitted_final.plot_diagnostics(figsize=(16, 8))
plt.show()

# Forecast the nest 4 periods of Sales Amount
fcast = sarima_fitted_final.get_forecast(4)
forecast_results = pd.DataFrame({'forecast_mean': fcast.predicted_mean,
                                 'forecast_high_95': fcast.conf_int(alpha= 0.05).iloc[:,1],
                                 'forecast_high_80': fcast.conf_int(alpha= 0.20).iloc[:,1],
                                 'forecast_low_80': fcast.conf_int(alpha= 0.20).iloc[:,0],
                                 'forecast_low_95': fcast.conf_int(alpha= 0.05).iloc[:,0],
                                })
forecast_results.index = pd.date_range(start=forecast_results.index[0] , periods=len(forecast_results), freq='MS')
forecast_results

# Visualize the forecast results
sales_data.plot(figsize=(18,10))
sarima_fitted_final.fittedvalues.plot(label = 'fitted value')
forecast_results.forecast_mean.plot()
upper_series_80 = forecast_results.forecast_high_80
lower_series_80 = forecast_results.forecast_low_80
upper_series_95 = forecast_results.forecast_high_95
lower_series_95 = forecast_results.forecast_low_95

plt.fill_between(upper_series_80.index,
                 lower_series_80,
                 upper_series_80,
                 color='k', alpha=.15)

plt.fill_between(lower_series_95.index,
                 lower_series_95,
                 upper_series_95,
                 color= None, linestyle ='--', alpha=.15)
plt.legend(loc = 'upper left', fontsize =15)
plt.xlabel('Year')
plt.ylabel('Monthly Sales in USD')
plt.title('Actual and Forecast Values', fontsize = 18)

"""# **Conclusion**
This analysis is mainly about forecasting for upcoming sales in a video game company. Firstly, I investigate and prepare the time series data. The provided data was appropriate to use time series models and I held out the last 4 periods of data points for validation. Then, I determined Trend, Seasonal and Error components in the data based on decomposition plots. After that, I analyse the data by applying the ARIMA and ETS models and describe the errors for both models. I compared the in-sample error measurements to both models and compare error measurements for the holdout sample in the forecast. Finally,I choose the best fitting model and forecast the next four periods.
"""

